{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "5c0372ed38b372118c24adb00d45654d76c8d10261533c5724e3f5fc1d75489a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import onnx\n",
    "import keras2onnx\n",
    "from numpy import random\n",
    "import onnxruntime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 11, 11, 16)        816       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 9, 9, 8)           1160      \n_________________________________________________________________\nflatten (Flatten)            (None, 648)               0         \n_________________________________________________________________\ndense (Dense)                (None, 2)                 1298      \n_________________________________________________________________\noutput (Dense)               (None, 1)                 3         \n=================================================================\nTotal params: 3,277\nTrainable params: 3,277\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (15,15,2)\n",
    "model_name_onnx = \"onnx_inference_model.onnx\"\n",
    "\n",
    "def create_model():\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape, name=\"input\"),\n",
    "            layers.Conv2D(16, kernel_size=(5, 5), activation=\"relu\"),\n",
    "            layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            #layers.Dropout(0.5),\n",
    "            layers.Dense(2, activation=\"relu\"),\n",
    "            layers.Dense(1, activation=\"sigmoid\", name=\"output\")\n",
    "        ]\n",
    "    )\n",
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "tf executing eager_mode: True\n",
      "tf.keras model eager_mode: False\n",
      "The ONNX operator number change on the optimization: 19 -> 13\n",
      "The maximum opset needed by this model is only 11.\n"
     ]
    }
   ],
   "source": [
    "onnx_model = keras2onnx.convert_keras(model, model.name)\n",
    "\n",
    "onnx.save_model(onnx_model, model_name_onnx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession(model_name_onnx)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[[0.82053363 0.9608356 ]\n   [0.06297879 0.38979977]\n   [0.09433876 0.27077416]\n   ...\n   [0.14184965 0.5104971 ]\n   [0.57435036 0.593198  ]\n   [0.01278451 0.02785275]]\n\n  [[0.21489012 0.537082  ]\n   [0.89448035 0.2835876 ]\n   [0.51925784 0.2712296 ]\n   ...\n   [0.1923579  0.49554566]\n   [0.02352868 0.04423856]\n   [0.74857223 0.7702438 ]]\n\n  [[0.64332545 0.86404943]\n   [0.19336165 0.8971832 ]\n   [0.27870715 0.88027805]\n   ...\n   [0.42786178 0.597311  ]\n   [0.42772645 0.19293176]\n   [0.9809513  0.4359652 ]]\n\n  ...\n\n  [[0.7908211  0.7975447 ]\n   [0.9569479  0.8067809 ]\n   [0.95295537 0.73899   ]\n   ...\n   [0.7408552  0.65267926]\n   [0.81699204 0.68511325]\n   [0.6640459  0.66994196]]\n\n  [[0.00835647 0.7393267 ]\n   [0.99204427 0.37042826]\n   [0.9554394  0.4849424 ]\n   ...\n   [0.9849971  0.5137958 ]\n   [0.481561   0.75081235]\n   [0.1843084  0.05024053]]\n\n  [[0.01669408 0.86375016]\n   [0.5922881  0.56586456]\n   [0.815541   0.9427222 ]\n   ...\n   [0.4906323  0.79118454]\n   [0.47980627 0.7250997 ]\n   [0.48909417 0.88350165]]]\n\n\n [[[0.32144448 0.9870067 ]\n   [0.8728869  0.5778745 ]\n   [0.7712964  0.46263662]\n   ...\n   [0.05261553 0.7318188 ]\n   [0.6821457  0.2534635 ]\n   [0.7457575  0.62446016]]\n\n  [[0.7735432  0.38191006]\n   [0.08252818 0.08588424]\n   [0.43163407 0.323869  ]\n   ...\n   [0.430179   0.03982203]\n   [0.48723003 0.96406263]\n   [0.32641572 0.24056412]]\n\n  [[0.6476983  0.6550369 ]\n   [0.7322107  0.8987885 ]\n   [0.9459084  0.17585807]\n   ...\n   [0.94482166 0.7709009 ]\n   [0.19739844 0.5615351 ]\n   [0.9663757  0.84159905]]\n\n  ...\n\n  [[0.79923296 0.3184395 ]\n   [0.97198147 0.07775129]\n   [0.6250977  0.937393  ]\n   ...\n   [0.5424171  0.11692066]\n   [0.76928663 0.12046888]\n   [0.8296401  0.00639482]]\n\n  [[0.03084351 0.4970827 ]\n   [0.6841856  0.5122625 ]\n   [0.3178826  0.01004547]\n   ...\n   [0.1227821  0.00116795]\n   [0.61338687 0.8407526 ]\n   [0.40742168 0.16040452]]\n\n  [[0.6898461  0.49626866]\n   [0.6470033  0.9179405 ]\n   [0.00655309 0.95496553]\n   ...\n   [0.48176172 0.6110351 ]\n   [0.7164137  0.6538558 ]\n   [0.51772267 0.7506744 ]]]\n\n\n [[[0.12406817 0.05238819]\n   [0.9874236  0.34217146]\n   [0.5023478  0.3383636 ]\n   ...\n   [0.69863105 0.06731867]\n   [0.4814953  0.08340683]\n   [0.99458617 0.6808195 ]]\n\n  [[0.16558859 0.5299166 ]\n   [0.36988926 0.0954927 ]\n   [0.18835273 0.19922814]\n   ...\n   [0.63575625 0.52700007]\n   [0.9649716  0.89229625]\n   [0.687361   0.7163241 ]]\n\n  [[0.5654204  0.19782151]\n   [0.7791033  0.9894567 ]\n   [0.8635034  0.49650595]\n   ...\n   [0.66435385 0.8400925 ]\n   [0.5248442  0.8841585 ]\n   [0.35376406 0.9070534 ]]\n\n  ...\n\n  [[0.0312733  0.8447765 ]\n   [0.05594271 0.40420294]\n   [0.20717673 0.5484055 ]\n   ...\n   [0.10192842 0.50158393]\n   [0.55508363 0.7673824 ]\n   [0.5972708  0.5062721 ]]\n\n  [[0.22562714 0.899949  ]\n   [0.2197692  0.3866319 ]\n   [0.39240983 0.87091184]\n   ...\n   [0.49473733 0.9696139 ]\n   [0.815416   0.35947376]\n   [0.36065185 0.86031145]]\n\n  [[0.46644118 0.11404447]\n   [0.00100055 0.5203791 ]\n   [0.96023613 0.45082396]\n   ...\n   [0.6120574  0.1370328 ]\n   [0.10312161 0.33662513]\n   [0.8202934  0.9736401 ]]]\n\n\n ...\n\n\n [[[0.69523084 0.12414266]\n   [0.7356941  0.55103934]\n   [0.6766919  0.8045161 ]\n   ...\n   [0.6682633  0.9954366 ]\n   [0.9020839  0.84924525]\n   [0.25656077 0.8821772 ]]\n\n  [[0.8658995  0.67944926]\n   [0.49961478 0.91620845]\n   [0.97463804 0.0423697 ]\n   ...\n   [0.11066779 0.39921573]\n   [0.905078   0.6145919 ]\n   [0.02450499 0.7908466 ]]\n\n  [[0.04080154 0.5764577 ]\n   [0.19147752 0.9803573 ]\n   [0.33273935 0.84321934]\n   ...\n   [0.19141686 0.990766  ]\n   [0.8788819  0.9868204 ]\n   [0.20171809 0.81403565]]\n\n  ...\n\n  [[0.90102005 0.19815871]\n   [0.931321   0.5985443 ]\n   [0.795806   0.32502812]\n   ...\n   [0.25005892 0.8270983 ]\n   [0.93851185 0.7257673 ]\n   [0.41150248 0.1101736 ]]\n\n  [[0.91399145 0.800031  ]\n   [0.92990804 0.4327832 ]\n   [0.55308974 0.9505044 ]\n   ...\n   [0.78486896 0.30111945]\n   [0.15228622 0.5105194 ]\n   [0.23098251 0.31778178]]\n\n  [[0.15386166 0.8657985 ]\n   [0.63868594 0.35760397]\n   [0.21465181 0.057499  ]\n   ...\n   [0.7042879  0.12967494]\n   [0.94664997 0.6088077 ]\n   [0.9796606  0.75966704]]]\n\n\n [[[0.28705108 0.7632038 ]\n   [0.41986793 0.18205115]\n   [0.7630661  0.7968441 ]\n   ...\n   [0.6567478  0.39573067]\n   [0.9726378  0.04262745]\n   [0.39851874 0.44881254]]\n\n  [[0.79606587 0.09134384]\n   [0.42926273 0.938902  ]\n   [0.5638032  0.10737244]\n   ...\n   [0.36401936 0.5377445 ]\n   [0.49760523 0.85521245]\n   [0.67641866 0.26435605]]\n\n  [[0.01170957 0.9828335 ]\n   [0.6737745  0.26563472]\n   [0.41954204 0.9249337 ]\n   ...\n   [0.48135725 0.7275949 ]\n   [0.888862   0.26284483]\n   [0.96990335 0.7503627 ]]\n\n  ...\n\n  [[0.9134882  0.13699475]\n   [0.25189576 0.4847943 ]\n   [0.19178388 0.7976643 ]\n   ...\n   [0.46476454 0.8452363 ]\n   [0.295067   0.07822362]\n   [0.78880787 0.44999167]]\n\n  [[0.5407851  0.22719358]\n   [0.80407834 0.58186543]\n   [0.7716783  0.10036018]\n   ...\n   [0.48653933 0.23553441]\n   [0.75429887 0.5294606 ]\n   [0.62417334 0.50992584]]\n\n  [[0.29403704 0.78694177]\n   [0.7673234  0.5590815 ]\n   [0.2887712  0.75831366]\n   ...\n   [0.00534842 0.28793755]\n   [0.34476608 0.55792105]\n   [0.28974062 0.6257028 ]]]\n\n\n [[[0.05393244 0.1482789 ]\n   [0.14841881 0.74424875]\n   [0.0835388  0.59136504]\n   ...\n   [0.4118558  0.88395196]\n   [0.72797805 0.68418163]\n   [0.87752014 0.83948684]]\n\n  [[0.4229582  0.50386363]\n   [0.98175424 0.22234097]\n   [0.64276105 0.8141688 ]\n   ...\n   [0.6039235  0.47108272]\n   [0.748776   0.78265655]\n   [0.65371674 0.51729715]]\n\n  [[0.66041934 0.40526116]\n   [0.03078103 0.22635804]\n   [0.92175627 0.30515525]\n   ...\n   [0.72358644 0.25093508]\n   [0.5320053  0.71990275]\n   [0.96946496 0.08645891]]\n\n  ...\n\n  [[0.99200827 0.70578504]\n   [0.27768838 0.82331705]\n   [0.35643327 0.9750696 ]\n   ...\n   [0.7428723  0.12132824]\n   [0.15600924 0.31378722]\n   [0.81964415 0.87752414]]\n\n  [[0.98263    0.30966204]\n   [0.53581274 0.52630794]\n   [0.875984   0.7709    ]\n   ...\n   [0.86023134 0.28784132]\n   [0.47219127 0.7832177 ]\n   [0.7921889  0.6877778 ]]\n\n  [[0.03479782 0.07825121]\n   [0.8054409  0.36542693]\n   [0.4106655  0.45218408]\n   ...\n   [0.28103647 0.902771  ]\n   [0.2336968  0.3457778 ]\n   [0.8287207  0.78239614]]]]\n<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data = random.rand(10000,input_shape[0],input_shape[1],input_shape[2]).astype(np.single)\n",
    "print(data)\n",
    "print(type(data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "starting inference\n",
      "inference ended in 9.35300064086914 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"starting inference\")\n",
    "start = time.time()\n",
    "for i in range(1000):\n",
    "    prediction = session.run(None, {\"input\": data} )\n",
    "duration = time.time() - start\n",
    "print(f\"inference ended in {duration} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}